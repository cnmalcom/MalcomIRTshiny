---
title: "IRT1 TAM Script For Class with 2 Examples"
author: "Kathleen Scalise"
date: "2022-09-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

set.seed(5878)
library(pacman)

pacman::p_load(TAM, WrightMap, RColorBrewer, ltm, psych)
```

## Data Set Introduction

Students worldwide "endorsed" their opinions on collaboration traits using a survey instrument. The associated data set is part of the 2015 OECD PISA and is a subset of the countries. The subset consists of the full Netherlands representative sample (representative by OECD terms) of 5,355 high school 15-year-old students. These students responded to 8 survey questions that were designed to consider some aspects of the students' attitudes about traits supposedly involved in collaboration, according to the OECD framework (construct). A much larger data set and the full code book for all countries and many more variables from the 2015 student questionnaire are also available at the OECD website. 

Here are the survey questions:

Country ID is in the first column (528 for the Netherlands, all cases here)

Prompt for the following items: To what extent do you disagree or agree with the following statements about yourself (Part ST082 of Student Survey)?

1. I prefer working as part of a team to working alone. (Item ST082Q01NA)

2. I am a good listener. (Item ST082Q02NA)

3. I enjoy seeing my classmates be successful. (Item ST082Q03NA)

4. I take into account what others are interested in. (Item ST082Q08NA)

5. I find that teams make better decisions than individuals. (Item ST082Q09NA)

6. I enjoy considering different perspectives. (Item ST082Q12NA)

7. I find that teamwork raises my own efficiency. (Item ST082Q13NA)

8. I enjoy cooperating with peers. (Item ST082Q14NA)

Same Likert scale for all survey indicators:

1 = "Strongly disagree"

2 = "Disagree"

3 = "Agree"

4= "Strongly Agree"

5 through 9 = missing (different codes for different types of missingness)

## Import the Data for Netherlands:
```{r import_data}
netherlands <- read.csv("", stringsAsFactors=FALSE)
```

## Clean Data for TAM Package

Omit the first column ID variable as it is the country code.
```{r clean_data}
netherlands2 <- netherlands[,-1]
```

## Descriptive Statistics

Below the psych package is used to look at basic descriptives for the item data in the raw score before calibrating the data (that is, before applying a measurement model).
```{r descrip_stats}
describe(netherlands2, na.rm = TRUE, interp=FALSE,skew = TRUE, ranges = TRUE,trim=.1,type=3,check=TRUE,fast=NULL,quant=NULL,IQR=FALSE,omit=FALSE,data=NULL)
```

```{r data_overview}
str(netherlands2)
```

Histograms of the 8 Items
Students tended to respond more with "disagree" and "agree".
```{r histograms}
par(mfrow = c(4,2))

HS1 <- hist(netherlands2$ST082Q01NA)

HS2 <- hist(netherlands2$ST082Q02NA)

HS3 <- hist(netherlands2$ST082Q03NA)

HS8 <- hist(netherlands2$ST082Q08NA)

HS9 <- hist(netherlands2$ST082Q09NA)

HS12 <- hist(netherlands2$ST082Q12NA)

HS13 <- hist(netherlands2$ST082Q13NA)

HS14 <- hist(netherlands2$ST082Q14NA)
```

## Save as Matrix for TAM package

Setting the data to "matrix" format for use with the TAM R library.
```{r convert_matrix}
#rename columns for plotting
colnames(netherlands2) <- c("Team","Listen","See","Engage","Decide","Lens","Better","Cooperate")

netherlands3 <- as.matrix(netherlands2) #save as matrix
head(netherlands3)
```

## Checking the Amount of Missing Data

Counts of each score per items 1 through 8. Scores of 7 & 9 indicate missing data.
```{r missingness}
table(netherlands2$Team)
table(netherlands2$Listen)
table(netherlands2$See)
table(netherlands2$Engage)
table(netherlands2$Decide)
table(netherlands2$Lens)
table(netherlands2$Better)
table(netherlands2$Cooperate)
```

% Missing Data
```{r percent_missing}
((145+36+145+38+145+35+145+40+145+44+145+72+145+67+145+41)/5355)*100
```

## Replace Missing Data & Descriptive Classical Test Theory (CCT) Information

Converted missing codes to NAs then used the descript function of ltm package to run some CTT descriptives where Freq = Frequency of NAs (missing data) for each item and % is the percent of NA data each item out of the total data sample. Finally, imputed missing values as mean of item.
```{r replace_missing_data}
netherlands3<-replace(netherlands3,netherlands3>4,NA)
netherlands3_Desc <- descript(netherlands3, n.print = 10, chi.squared = FALSE, B = 1000)
netherlands3_Desc$missin

#replace missing values by compute rounded mean
for(i in 1:ncol(netherlands3)) {                                   
  netherlands3[ , i][is.na(netherlands3[ , i])] <-round(mean(netherlands3[ , i], na.rm = TRUE), digits=0)}
netherlands3_Desc <- descript(netherlands3, n.print = 10, chi.squared = FALSE, B = 1000)
netherlands3_Desc$missin
```

For Cronbach's alpha, which measures scale reliability, all items have a medium coefficient over 6.5. Removing one item at a time does not decrease reliability and in some cases, such as excluding the listen item it makes the reliability stronger then using all the items together.
```{r CTT_descriptives}
#Number of items, number of sample units
netherlands3_Desc$sample

#Percentage of negative and positive responses for each item (each row adds to 1) for each score category
netherlands3_Desc$perc

#Matrix of p-values for pairwise association between the items
netherlands3_Desc$pw.ass #null because not dichotomous for Netherlands data set

#Numeric vector of sample estimates for the biserial correlation of dichotomous manifest variables with the total score (the latter calculated by excluding the specific item)
netherlands3_Desc$bisCorr #null because no chi-square calcs for Netherlands data set

#Matrix of Cronbach's alpha, overall = 0.72
netherlands3_Desc$alpha
```

## Rescore Item Categories

For future output in the Wright Map, the score categories 1-4 need to be scored as 0-3, so rescored these categories below.
```{r rescores}
#rescore data so categories 1-4 are 0-3
netherlands3[netherlands3==1] <- 0
netherlands3[netherlands3==2] <- 1
netherlands3[netherlands3==3] <- 2
netherlands3[netherlands3==4] <- 3
netherlands3_Desc$perc

```

## Run IRT Rasch Model 1

TAM will fit the simplest IRT model, the Rasch model, by default.
```{r Netherlands_IRT_mod1, results='hide'}
mod1_Netherlands <- tam.mml(resp=netherlands3, constraint="items")
#constraint sets sum constraint for parameter identification, which is items, or can be set to cases
```

## Interpreting Results

Running the model shows the EM iterations of the estimation and finally gives the item parameter estimates and the EAP reliability if the model converges. If so, the results of the IRT run are encapsulated in the object called "mod_Netherlands". The summary command was run to see results.

Interations = 100
Deviance - A measure of error with lower deviance indicating the model is a better fit for the data and higher deviance indicates that the model fits worse to the data when compared to a best case (saturated) model.
Log likelihood - A measure of goodness of fit when comparing models where the model with the highest value is the best fitting - describes how likely the model is given the data.
AIC - Lower AIC values indicate a better fitting model. Penalizes models with more parameters.
BIC - Lower BIC values indicate less penalties towards the model, which means better model fit.
EAP Reliability - Estimation of test reliability.
Covariances & Variances - The directional relationship between the variables and spread of data around the mean.
Correlations & SD - Degree of association and amount of variation in the data set.
Regression Coefficients (parameter Î²) - The amount x must be multiplied by to give a corresponding change in y or amount y changes for a unit increase in x.
Alpha parameter - fixed to 1 as ran a Rasch model
```{r summary_Netherlands_mod1}
summary(mod1_Netherlands)
```

Estimated item difficulties (xsi in logits) and standard errors (se.xsi). Standard errors can help identify if item difficulties overlap. Higher item difficulties indicate harder items while low xsi values indicate easier items.
```{r access_vars}
mod1_Netherlands$xsi
```

Save only the item difficulties
```{r access_deeper}
ItemDiff<-mod1_Netherlands$xsi$xsi #accessed via the sub-sub-variable
```

```{r}
mean(ItemDiff)
```

```{r}
sd(ItemDiff)
```

Structure of the analysis
```{r structure_Nether_mod1}
structure(mod1_Netherlands)
```

# Model Fit Information for the Rasch Model

Infit and Infit_t columns help to understand model fit to the assumed alpha=1 of the Rasch model. Infit is for inlier-sensitive fit statistic based on the squared standardized residual between observed and expected on the basis of the model. Outfit is for outlier-sensitive fit statistic that is not weighted like the Infit statistic. The _t indicates t values for the statistic while _p is the p-value. Range is from 0 to infinity for both with an expectation of 1. Values above or below 1 may indicate different types of misfit. Values + or - 2 may warrent closer inspection. One typical tolerance is 3/4-4/3 for Infit, with if outside these tolerance limits then T>1.96 or less than -1.96 for significance. Negative T is overfitting (too sharp to the S curve) and positive T is underfitting (too flat to the S curve, with usually too flat of more concern for information). The participants appear to be behaving consistently with the model.
```{r fit Nether_mod1}
Fit <- tam.fit(mod1_Netherlands)
summary(Fit)
```

```{r}
range(Fit$itemfit$Infit)
```

# Plotting Item Characteristic Curves for the Rasch model

Plotting gives the expected item characteristic curves based on the model (expected) compared to the observed data, for each item. The reliability and the dataset size are too small for interpretation. The ICC for the item "Better" is shown below and illustrates that the observed (black) line is slightly off target from the expected (blue) line around ability level 1 to 2. 
```{r plot_icc_Nether_mod1}
png(file = "/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots/Ngraph1.png")

plot(mod1_Netherlands)
```

##

![](/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots/Ngraph1.png)

# Generate SEM plot

Generate a simple SEM plot assuming dichotomous data as here, to show the standard error for persons across the latent trait. More about showing persons estimates is discussed below. This plot helps understand how well the instrument is measuring across the latent trait abilities given the data set.
```{r plot_sem_Nether_mod1}
SE.EAP <- mod1_Netherlands$person$SD.EAP / sqrt(mod1_Netherlands$person$max)
#give the plot a file name
png(file = "/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots/Ngraph2.png")
plot(mod1_Netherlands$person$EAP,SE.EAP)
```

##

![](/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots/Ngraph2.png)

# Getting the Person Estimates:

You can also access the person estimates individually, which are provided as eap by default in the TAM package along with other information about the estimates. Code here will not print results because they are too long, can adjust script to write to a file, see below.
```{r get_person_estimates, include=FALSE}
mod1_Netherlands$person
#View(mod1_Netherlands$person)
```

For some plots, you need just the person estimates alone, so access the sub-sub-variable.  Code here will not print results because they are too long, can adjust script to write to a file, see below.
```{r get_vars_person_estimates, include=FALSE}
PersonAbility <- mod1_Netherlands$person$EAP
```

To get various simple displays of some estimates, for example:
```{r displays_person_estimates}
#hist(PersonAbility)
#hist(ItemDiff)
#mean(ItemDiff)
#mean(PersonAbility)
#sd(ItemDiff)
#sd(PersonAbility)
```

If you want to use other ability estimates rather than the TAM default EAPs, TAM can also do other estimates, such as wle. This will also give you the person separation reliability based on mle described below. 

There can be numerous considerations about which person estimates you may want to select, and considerations are beyond the scope of this course. Default generally works in this class. You may want another such as wle to have an additional reliability comparator.

```{r wle_person_estimates}
Abil <- tam.wle(mod1_Netherlands)
PersonAbility_mle <- Abil$theta
```

# Person Separation Reliability:

This is a form of test reliability based on the raw score; you should compare it to the modeled reliability, such as EAP reliability in your model estimate above. The results should be reasonably close in absence of much missing data (for example, .596 on EAP reliability and .497 on person separation reliability was the comparison in this class data set, both of which indicate poor reliability and that more information is needed at the right level of the latent trait to make reliable estimates). Often reliabilities differ more than this, for instance by several integer values but they indicate in the same general direction. However, if reliabilities indicate very different directions, this is a point to be investigated. Results were already reported, but to get the person separation reliability on the wle above directly again:

```{r wle_reliability}
mean(Abil$WLE.rel)
```

# Getting More Classical Information from TAM directly:

Now that a model has been fit and some person estimates obtained, more classical test theory item statistics are available in TAM, similar to what we saw in ltm but here we want the person ability for the TAM ctt function so helpful to run with the model. Note that in the results, the rpb.WLE for dichotomous is the ordinary point biserial correlation of an item and a test score (here the WLE), and for polytomous of a step and a test score.
```{r ctt_dataset}
ctt_Ex2 <- tam.ctt(netherlands3, PersonAbility)
ctt_Ex2
```

# Running polytomous data in TAM:

TAM automatically detects that some item responses are partial credit (maximum score more than 1). In this case, TAM will fit a Rasch partial credit model by default. So there is nothing to change if you have polytomous data.

You will get different output. Note that item parameters are sometimes known as the "delta" parameters, as in Masters' derivation of the partial credit model (Masters, 1982). The delta parameters are the intersection points of adjacent category probability curves. They are useful for the mathematical formulation of the partial credit model. They are NOT useful for interpreting item difficulties of the response categories. For this, Thurstonian thresholds are used. Helpful output is the Wright map.

For each individual item and score category, the Thurstonian threshold is estimated. The Thurstonian threshold is the estimated point on the latent variable (in the context of the particular item) at which the probability of being observed anywhere below a given score category is equal that of being observed in or anywhere above that score category.

Note that in the TAM package, different items can have different numbers of score categories, for instance some items can be dichotomous and others have different numbers of polytomous scores. If any score category is not endorsed, however, you should be aware of this for the analysis results. 

# Generating some Plots from TAM output:

You will need both the persons ability estimates and the Thurstonian thresholds for Wright Maps. Persons ability estimates are generated above (see PersonAbility object). To generate Thurstonian thresholds:
```{r generating_thurstonian_thresholds}
tthresh <- tam.threshold(mod1_Netherlands)
tthresh
```

You may wish to plot the thresholds alone, such as below in a scatterplot. Be sure to use the Plots Zoom tool in Rstudio to click on the plot and see it better when viewing within Rstudio.The thresholds are marked as Cat1 thresholds on the y-axis for each item in the plot. If this were polytomous data, you would see category thresholds for moving to each additional category.

```{r plotting_tthresholds}
png(file = "/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots/dotchart.png")
par(ps=9)
dotchart(t(tthresh), pch=19)
```

##

![](/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots/dotchart.png)

You may want to plot the thresholds and person ability on the same scale:
```{r plotting_ability_and_tthreshold}
png(file = "/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots/hist_PersonAbility.png")
hist(PersonAbility,xlim=c(-3,3),breaks=20)
png(file = "/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots/hist_thresholds.png")
hist(tthresh,xlim=c(-3,3),breaks=20)
```

##

![](/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots/hist_PersonAbility.png)

##

![](/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots/hist_thresholds.png)

Here from the histograms, you can see that the thresholds are in general "easier" to achieve or endorse than where the people are estimated on the latent trait, for this data set. So the alignment is not great. Some "harder" to achieve or endorse items would probably provide more information on the persons in this case. This comparison can be see more easily in the Wright map, where the persons and items are plotted together and on the same scale.

# Generating Wright Map from TAM output:

The Wright Map is also called an Item-Persons map. It can be easier to understand the results of a calibration if the person and item results are displayed together like this, possible for Rasch family models and 1PL.

```{r generate_WrightMap}
png(file = "/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots/WrightMap1.png")
wrightMap(PersonAbility,tthresh)
```

##

![](/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots/WrightMap1.png)

As usual for R plots, there are many options to customize your WrightMap and make it more readable. These include graph axis labels, changing size and types of symbols, and adding item plotting labels. Here is an example, Set2 is one of color blind friendly palettes. 

```{r item_level_symbols_WrightMap}
#itemlevelcolors <- matrix(rep(brewer.pal(4, "Set1"), 10), byrow = TRUE, ncol = 4)

itemlevelcolors <- matrix(rep(brewer.pal(4, "Set2"), 8), byrow = TRUE, ncol = 4)
png(file = "/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots//WrightMap2.png")
wrightMap(PersonAbility,tthresh,
          show.thr.lab = FALSE,
          thr.sym.cex = 2.5,
          thr.sym.pch = 17,
          thr.sym.col.fg = itemlevelcolors, 
          thr.sym.col.bg = itemlevelcolors,
          main.title   = "Wright Map",
          axis.logits  = "Latent Trait",
          axis.persons = "Person Distribution",
          axis.items   = "Survey Questions")
```

##

![](/Users/cassiemalcom/Desktop/CM2020/22_Fall Term Classes/EDLD 661 IRT/EDLD661_r/Plots/WrightMap2.png)

# Running 2PL and 3PL models in TAM

We discuss slightly more complex IRT models in the  class. You can run TAM for the 2PL model, on both dichotomous and polytomous data, see below comment out. You can also run unidimensional and multidimensional (MD) models. (MD is not discussed in this class, see IRT 2 for this topic).
```{r run_TAM_IRT_model_2PL}
mod_2_Netherlands <- tam.mml.2pl(resp=netherlands3)
summary(mod_2_Netherlands)
```

You can run TAM for the 3PL model only on dichotomous data the last I looked. The run below is commented out because you will want to use a more complex data set that involves guessing for 3PL models. There are other approaches if you need more than TAM for 3PL, 4 PL etc. See below for a general discussion of viewing IRT within a SEM framework, for those who have had SEM coursework. 

```{r run_TAM_IRT_model_3PL}
#mod_3_Netherlands <- tam.mml.3pl(resp=netherlands3)
#summary(mod_3_Netherlands)
```

If you are familiar with SEM and would like a link to a discussion of IRT from a SEM perspective: 
https://m-clark.github.io/sem/item-response-theory.html

# Some additional Basic R Functions and other links that may  be helpful

IRT class R primer info is based on Desjardins' Introduction To R and R Studio. 

To log your Console in R Studio:
```{r log_console}
#sink("myfilename_kms", append=FALSE, split=TRUE)
```
To install and library packages to read SPSS files
```{r read_SPSS_files}
#install.packages("foreign") #commented out because install just once
#library(foreign) 
```